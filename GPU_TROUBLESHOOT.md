# GPU æ”¯æŒæ•…éšœæ’é™¤æŒ‡å—

## ğŸ” é—®é¢˜è¯Šæ–­

å¦‚æœçœ‹åˆ° `NVIDIA-SMI couldn't find libnvidia-ml.so library` é”™è¯¯ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¯Šæ–­ï¼š

### 1. æ£€æŸ¥å®¿ä¸»æœº NVIDIA é©±åŠ¨
```bash
nvidia-smi
```
åº”è¯¥æ˜¾ç¤º GPU ä¿¡æ¯ã€‚å¦‚æœå¤±è´¥ï¼Œéœ€è¦å®‰è£… NVIDIA é©±åŠ¨ã€‚

### 2. æ£€æŸ¥ NVIDIA Container Toolkit
```bash
# æ£€æŸ¥æ˜¯å¦å®‰è£…
which nvidia-container-runtime

# å¦‚æœæœªå®‰è£…ï¼Œå®‰è£… NVIDIA Container Toolkit
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### 3. æ£€æŸ¥ Docker é…ç½®
```bash
# æ£€æŸ¥ daemon.json
cat /etc/docker/daemon.json

# åº”è¯¥åŒ…å«:
{
    "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    },
    "default-runtime": "nvidia"
}
```

### 4. æµ‹è¯• Docker GPU æ”¯æŒ
```bash
# æµ‹è¯•åŸºç¡€ CUDA å®¹å™¨
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# å¦‚æœæˆåŠŸï¼Œæµ‹è¯•æˆ‘ä»¬çš„é•œåƒ
docker run --rm --gpus all ghcr.io/sebastian0619/index-tts:latest nvidia-smi
```

## ğŸ”§ å¿«é€Ÿä¿®å¤

### é€‰é¡¹ 1: é‡æ–°é…ç½® Docker Compose
```bash
# åœæ­¢å®¹å™¨
docker-compose down

# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ GPU é…ç½®é‡å¯
docker-compose up -d
```

### é€‰é¡¹ 2: ä½¿ç”¨ CPU æ¨¡å¼
å¦‚æœ GPU æš‚æ—¶æ— æ³•å·¥ä½œï¼Œå¯ä»¥ä½¿ç”¨ CPU æ¨¡å¼ï¼š
```bash
# å¯åŠ¨ CPU ç‰ˆæœ¬
docker-compose --profile cpu-only up -d indextts-cpu
```

### é€‰é¡¹ 3: æ‰‹åŠ¨è¿è¡Œå®¹å™¨
```bash
# æ‰‹åŠ¨æµ‹è¯•å®¹å™¨
docker run --rm -it --gpus all \
  -p 7860:7860 \
  -v ./checkpoints:/app/checkpoints \
  ghcr.io/sebastian0619/index-tts:latest bash

# åœ¨å®¹å™¨å†…æµ‹è¯•
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“‹ å¸¸è§é—®é¢˜

1. **é©±åŠ¨ç‰ˆæœ¬ä¸å…¼å®¹**: CUDA 12.8 éœ€è¦é©±åŠ¨ç‰ˆæœ¬ >= 535.54
2. **Container Toolkit æœªå®‰è£…**: éœ€è¦å®‰è£… nvidia-container-toolkit
3. **Docker é…ç½®é”™è¯¯**: éœ€è¦æ­£ç¡®é…ç½® /etc/docker/daemon.json
4. **æƒé™é—®é¢˜**: ç¡®ä¿ Docker æœ‰æƒé™è®¿é—® GPU è®¾å¤‡

## ğŸ†˜ å¦‚æœä»æœ‰é—®é¢˜

1. é‡å¯ Docker æœåŠ¡: `sudo systemctl restart docker`
2. é‡å¯ç³»ç»Ÿä»¥ç¡®ä¿é©±åŠ¨æ­£ç¡®åŠ è½½
3. æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—: `dmesg | grep -i nvidia`
4. ä½¿ç”¨ CPU æ¨¡å¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
